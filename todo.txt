- scraper 
create class to store new data - inherit from it for tweet vs news site etc
catch newspaper.article.ArticleException

- analyzer
use worker pool to chew queue
process data based on class type of data taken off queue - ie tweet vs site
on tweets: process @ better -> link to a person if someone @'s them?
            proess # better -> break into works and include in sentiment?

- general
logging
make real math model

- dependencies:
TextBlob
newspaper3k