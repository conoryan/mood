- scraper 
push "Article `download()` failed with 404 Client Error: Not Found for url: http://directory.nydailynews.com/news/politics/ny-news-house-democrats-investigation-trump-conspiracy-20180824-story.html on URL http://directory.nydailynews.com/news/politics/ny-news-house-democrats-investigation-trump-conspiracy-20180824-story.html
Skipping http://directory.nydailynews.com/news/politics/ny-news-house-democrats-investigation-trump-conspiracy-20180824-story.html due to Article exception"
  BACK onto queue... seems to work usually? or just reprocess then and there?
one time memoization doesn't work for some sources? may need to track articles
  and filter manually
wsj never gets date.

- analyzer
use worker pool to chew queue
on tweets: process @ better -> link to a person if someone @'s them?
          easier: just break it up and incorp into noun_phrases

- general
logging

- dependencies:
sqlite3
TextBlob
newspaper3k
vaderSentiment
wordninja